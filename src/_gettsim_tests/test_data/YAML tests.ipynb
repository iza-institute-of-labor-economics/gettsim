{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683baad4-15e5-4b48-bd10-7981f4acd541",
   "metadata": {},
   "source": [
    "# Converting Tests into Yaml-Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73551d98-1e1b-4dec-9977-94b70c7c86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from _gettsim_tests import TEST_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea985434",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_columns = [\n",
    "    \"note\",\n",
    "    \"Note\",\n",
    "    \"notes\",\n",
    "    \"comment\",\n",
    "    \"Comment\",\n",
    "    \"Notes on Entgeltpunkte\",\n",
    "    \"Notes on Regelaltersgrenze\",\n",
    "]\n",
    "source_columns = [\"source\", \"Source\", \"Quelle Arbeitgeber\"]\n",
    "\n",
    "roles = {\n",
    "    \"renten_alter\": {\n",
    "        \"in_provided\": [\n",
    "            # TODO: What are the inputs?\n",
    "            # \"p_id\",\n",
    "            # \"hh_id\",\n",
    "            # \"tu_id\",\n",
    "            # \"alter\",\n",
    "            # \"jahr\",\n",
    "            # \"geburtsjahr\",\n",
    "            # \"geburtsmonat\",\n",
    "            # \"m_arbeitsunfähig\",\n",
    "            # \"m_krank_ab_16_bis_24\",\n",
    "            # \"m_mutterschutz\",\n",
    "            # \"m_arbeitslos\",\n",
    "            # \"m_ausbild_suche\",\n",
    "            # \"m_schul_ausbild\",\n",
    "            # \"m_alg1_übergang\",\n",
    "            # \"m_geringf_beschäft\",\n",
    "            # \"weiblich\",\n",
    "            # \"y_pflichtbeitr_ab_40\",\n",
    "            # \"m_pflichtbeitrag\",\n",
    "            # \"m_freiw_beitrag\",\n",
    "            # \"m_ersatzzeit\",\n",
    "            # \"m_kind_berücks_zeit\",\n",
    "            # \"m_pfleg_berücks_zeit\",\n",
    "        ],\n",
    "        \"out\": [\n",
    "            # TODO: what are the targets?\n",
    "            # \"ges_rente_regelaltersgrenze\",\n",
    "            # \"ges_rente_frauen_altersgrenze\",\n",
    "            # \"_ges_rente_langj_altersgrenze\",\n",
    "            # \"_ges_rente_besond_langj_altersgrenze\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_csv_files() -> list[Path]:\n",
    "    return list(TEST_DATA_DIR.glob(\"*.csv\"))\n",
    "\n",
    "\n",
    "def read_file(file_name: str) -> pd.DataFrame:\n",
    "    return (\n",
    "        pd.read_csv(TEST_DATA_DIR / file_name, header=0, index_col=0, encoding=\"utf-8\")\n",
    "        .squeeze(\"columns\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def unique_years(df: pd.DataFrame, column_name: str = \"jahr\") -> list[int]:\n",
    "    return sorted(df[column_name].unique())\n",
    "\n",
    "\n",
    "def grouped_by_year(\n",
    "    df: pd.DataFrame, column_name: str = \"jahr\"\n",
    ") -> dict[int, pd.DataFrame]:\n",
    "    return {year: df[df[column_name] == year] for year in unique_years(df, column_name)}\n",
    "\n",
    "\n",
    "def columns_by_role(\n",
    "    df: pd.DataFrame, name: str\n",
    ") -> tuple[list[str], list[str], list[str], list[str], list[str]]:\n",
    "    out_cols = roles[name][\"out\"] if name in roles and \"out\" in roles[name] else []\n",
    "    in_cols_assumed = (\n",
    "        roles[name][\"in_assumed\"]\n",
    "        if name in roles and \"in_assumed\" in roles[name]\n",
    "        else []\n",
    "    )\n",
    "    in_cols_provided = (\n",
    "        roles[name][\"in_provided\"]\n",
    "        if name in roles and \"in_provided\" in roles[name]\n",
    "        else []\n",
    "    )\n",
    "\n",
    "    note_cols = [col for col in df if col in note_columns]\n",
    "    source_cols = [col for col in df if col in source_columns]\n",
    "\n",
    "    return in_cols_provided, in_cols_assumed, out_cols, note_cols, source_cols\n",
    "\n",
    "\n",
    "def create_yaml(df: pd.DataFrame, name: str) -> dict[str, dict]:\n",
    "    (\n",
    "        in_cols_provided,\n",
    "        in_cols_assumed,\n",
    "        out_cols,\n",
    "        note_cols,\n",
    "        source_cols,\n",
    "    ) = columns_by_role(df, name)\n",
    "\n",
    "    df.replace(to_replace=np.nan, value=None, inplace=True)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    def df_to_dict(df: pd.DataFrame) -> dict:\n",
    "        source = \"\\n\\n\".join(\n",
    "            value_to_string(df[source_column].iloc[0])\n",
    "            for source_column in source_cols\n",
    "            if value_to_string(df[source_column].iloc[0]) != \"\"\n",
    "        )\n",
    "        note = \"\\n\\n\".join(\n",
    "            value_to_string(df[note_column].iloc[0])\n",
    "            for note_column in note_cols\n",
    "            if value_to_string(df[note_column].iloc[0]) != \"\"\n",
    "        )\n",
    "        specs = {\"note\": note, \"source\": source}\n",
    "\n",
    "        inputs = {\n",
    "            \"provided\": df[in_cols_provided].to_dict(\"list\"),\n",
    "            \"assumed\": df[in_cols_assumed].to_dict(\"list\"),\n",
    "        }\n",
    "        outputs = df[out_cols].to_dict(\"list\")\n",
    "        return {\"info\": specs, \"inputs\": inputs, \"outputs\": outputs}\n",
    "\n",
    "    if \"hh_id\" in df:\n",
    "        for hh_id in sorted(df[\"hh_id\"].unique()):\n",
    "            df_hh = df.loc[df[\"hh_id\"] == hh_id]\n",
    "            out[f\"hh_id_{hh_id}\"] = df_to_dict(df_hh)\n",
    "    else:\n",
    "        out[\"hh_id_unknown\"] = df_to_dict(df)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def value_to_string(value: Any) -> str:\n",
    "    if pd.isnull(value):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "def write_yaml_to_file(\n",
    "    out: dict[str, dict], name: str, year: Optional[int] = None\n",
    ") -> None:\n",
    "    text = yaml.dump(out, sort_keys=False, allow_unicode=True, indent=2, width=88)\n",
    "    if year is None:\n",
    "        path = TEST_DATA_DIR / name / f\"{name}.yaml\"\n",
    "    else:\n",
    "        path = TEST_DATA_DIR / name / f\"{year}.yaml\"\n",
    "\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Writing to {path}\")\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(text)\n",
    "\n",
    "\n",
    "def convert_test_data() -> None:\n",
    "    for path in list_csv_files():\n",
    "        df = read_file(path)\n",
    "        name = path.stem\n",
    "\n",
    "        if \"jahr\" not in df:\n",
    "            yaml_out = create_yaml(df, name)\n",
    "            write_yaml_to_file(yaml_out, name)\n",
    "        else:\n",
    "            for year, year_df in grouped_by_year(df).items():\n",
    "                yaml_out = create_yaml(year_df, name)\n",
    "                write_yaml_to_file(yaml_out, name, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a53932",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_csv_files():\n",
    "    print(f'\"{file.stem}\": {\"{}\"},')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f59b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_test_data()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
